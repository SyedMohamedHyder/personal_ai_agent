{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "909504c5-55a6-4039-95ab-42f694958432",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import gradio as gr\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# RAG imports\n",
    "import numpy as np\n",
    "from sklearn.manifold import TSNE\n",
    "import plotly.graph_objects as go\n",
    "from langchain_chroma import Chroma\n",
    "\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.document_loaders import (\n",
    "    TextLoader,\n",
    "    DirectoryLoader,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03632583-d872-4521-a1e5-802c5374d9b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "\n",
    "MODEL = \"gpt-4o-mini\"\n",
    "VECTOR_DB = \"../vector_db\"\n",
    "KNOWLEDGE_BASE = \"../knowledge-base/linkedin\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3761976-a6de-479f-bb87-7889bd5d9afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables from .env\n",
    "\n",
    "load_dotenv(override=True)\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\", \"your-key-if-not-using-env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "690d51d2-c3d6-4aad-9a38-6210eecec333",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_metadata(doc, doc_type):\n",
    "    \"\"\"\n",
    "    Add a 'doc_type' field to the document's metadata.\n",
    "\n",
    "    Args:\n",
    "        doc (Document): The document to annotate.\n",
    "        doc_type (str): The type or source folder of the document.\n",
    "\n",
    "    Returns:\n",
    "        Document: The updated document with added metadata.\n",
    "    \"\"\"\n",
    "    doc.metadata[\"doc_type\"] = doc_type\n",
    "    return doc\n",
    "\n",
    "\n",
    "def load_folder_documents(folder):\n",
    "    \"\"\"\n",
    "    Load all markdown documents from a given folder and tag them with metadata.\n",
    "\n",
    "    Args:\n",
    "        folder (str): Path to the folder containing documents.\n",
    "\n",
    "    Returns:\n",
    "        list: List of documents with metadata added.\n",
    "    \"\"\"\n",
    "    doc_type = os.path.basename(folder)\n",
    "    loader = DirectoryLoader(\n",
    "        folder,\n",
    "        glob=\"**/*\",\n",
    "        loader_cls=TextLoader,\n",
    "        loader_kwargs={\"encoding\": \"utf-8\"},\n",
    "    )\n",
    "    folder_docs = loader.load()\n",
    "    return [add_metadata(doc, doc_type) for doc in folder_docs]\n",
    "\n",
    "\n",
    "def load_documents(folders):\n",
    "    \"\"\"\n",
    "    Load documents from a list of folders.\n",
    "\n",
    "    Args:\n",
    "        folders (list): List of folder paths.\n",
    "\n",
    "    Returns:\n",
    "        list: Combined list of documents from all folders.\n",
    "    \"\"\"\n",
    "    documents = []\n",
    "    for folder in folders:\n",
    "        documents.extend(load_folder_documents(folder))\n",
    "    return documents\n",
    "\n",
    "\n",
    "def load_documents_from_knowledge_base(knowledge_base: str):\n",
    "    \"\"\"\n",
    "    Load all documents from the specified knowledge base directory.\n",
    "\n",
    "    Uses the provided knowledge_base path (can include wildcards) to find all folders,\n",
    "    then loads and tags markdown documents within those folders.\n",
    "\n",
    "    Args:\n",
    "        knowledge_base (str): Path to the knowledge base directory or pattern (e.g., \"knowledge-base/*\").\n",
    "\n",
    "    Returns:\n",
    "        list: A list of LangChain Document objects with added metadata.\n",
    "    \"\"\"\n",
    "    folders = glob.glob(f\"{knowledge_base}/*\")\n",
    "    return load_documents(folders)\n",
    "\n",
    "\n",
    "def split_into_chunks(documents, chunk_size=1000, chunk_overlap=200):\n",
    "    \"\"\"\n",
    "    Split documents into smaller text chunks for processing.\n",
    "\n",
    "    Args:\n",
    "        documents (list): List of LangChain Document objects.\n",
    "        chunk_size (int): Maximum size of each chunk.\n",
    "        chunk_overlap (int): Number of overlapping characters between chunks.\n",
    "\n",
    "    Returns:\n",
    "        list: List of chunked Document objects.\n",
    "    \"\"\"\n",
    "    splitter = CharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
    "    return splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc3ea98-dfa3-4975-ad89-8d9f13c5d9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = load_documents_from_knowledge_base(KNOWLEDGE_BASE)\n",
    "chunks = split_into_chunks(documents)\n",
    "\n",
    "print(f\"Total documents: {len(documents)}\")\n",
    "print(f\"Total chunks: {len(chunks)}\")\n",
    "print(f\"Document types: {set(doc.metadata['doc_type'] for doc in documents)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3835ffbe-e3a8-4ddb-8197-8ed2d0d229a0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def create_vectorstore(chunks, persist_directory, overwrite=True):\n",
    "    \"\"\"\n",
    "    Create a Chroma vector store from document chunks.\n",
    "\n",
    "    Args:\n",
    "        chunks (list): List of document chunks to embed and store.\n",
    "        persist_directory (str): Directory path where the vector store will be saved.\n",
    "        overwrite (bool): If True, deletes existing collection before creating a new one.\n",
    "\n",
    "    Returns:\n",
    "        Chroma: The created Chroma vector store instance.\n",
    "    \"\"\"\n",
    "    embeddings = OpenAIEmbeddings()\n",
    "\n",
    "    if overwrite and os.path.exists(persist_directory):\n",
    "        Chroma(\n",
    "            persist_directory=persist_directory, embedding_function=embeddings\n",
    "        ).delete_collection()\n",
    "\n",
    "    vectorstore = Chroma.from_documents(\n",
    "        documents=chunks, embedding=embeddings, persist_directory=persist_directory\n",
    "    )\n",
    "\n",
    "    return vectorstore\n",
    "\n",
    "\n",
    "vectorstore = create_vectorstore(chunks, VECTOR_DB)\n",
    "print(f\"Vectorstore created with {vectorstore._collection.count()} documents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea08a5cb-1b52-458b-abf7-1928a4858ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_collection(vectorstore):\n",
    "    \"\"\"\n",
    "    Retrieve the underlying collection from a Chroma vector store.\n",
    "\n",
    "    Args:\n",
    "        vectorstore (Chroma): An instance of the Chroma vector store.\n",
    "\n",
    "    Returns:\n",
    "        Collection: The internal collection object.\n",
    "    \"\"\"\n",
    "    return vectorstore._collection\n",
    "\n",
    "\n",
    "def inspect_vectorstore(collection):\n",
    "    \"\"\"\n",
    "    Inspect the contents of a Chroma vector store collection.\n",
    "\n",
    "    Prints the number of vectors and their embedding dimensionality.\n",
    "\n",
    "    Args:\n",
    "        collection: The underlying Chroma collection object.\n",
    "    \"\"\"\n",
    "    count = collection.count()\n",
    "\n",
    "    sample = collection.get(limit=1, include=[\"embeddings\"])\n",
    "    embeddings = sample.get(\"embeddings\", [])\n",
    "\n",
    "    if len(embeddings) > 0:\n",
    "        dimensions = len(embeddings[0])\n",
    "        print(\n",
    "            f\"There are {count:,} vectors with {dimensions:,} dimensions in the vector store\"\n",
    "        )\n",
    "    else:\n",
    "        print(\"No embeddings found in the vector store.\")\n",
    "\n",
    "\n",
    "collection = get_collection(vectorstore)\n",
    "inspect_vectorstore(collection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84cbc27-54a0-459e-92b8-689d467e6e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all vectors, documents, and metadata from the collection\n",
    "result = collection.get(include=[\"embeddings\", \"documents\", \"metadatas\"])\n",
    "\n",
    "vectors = np.array(result[\"embeddings\"])\n",
    "documents = result[\"documents\"]\n",
    "metadatas = result[\"metadatas\"]\n",
    "\n",
    "# Extract 'doc_type' from each metadata dictionary\n",
    "doc_types = [metadata.get(\"doc_type\", \"unknown\") for metadata in metadatas]\n",
    "\n",
    "# Map doc_types to dark colors\n",
    "color_map = {\n",
    "    \"profile\": \"#1e3a8a\",          # Deep blue for profile information\n",
    "    \"experience\": \"#065f46\",        # Dark green for work experience and career\n",
    "    \"education\": \"#7c2d12\",         # Brown for education and academic achievements\n",
    "    \"skills\": \"#ca8a04\",           # Gold for skills and competencies\n",
    "    \"certifications\": \"#7c3aed\",   # Purple for certifications and credentials\n",
    "    \"projects\": \"#ea580c\",         # Orange for projects and portfolio work\n",
    "    \"publications\": \"#dc2626\",     # Red for publications and written work\n",
    "    \"networking\": \"#0d9488\",       # Teal for connections and networking\n",
    "    \"communications\": \"#059669\",   # Green for messages and communications\n",
    "    \"preferences\": \"#6b7280\",      # Gray for settings and preferences\n",
    "}\n",
    "\n",
    "# Assign colors to each vector based on its doc_type\n",
    "colors = [color_map.get(doc_type, \"gray\") for doc_type in doc_types]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2195bc2c-a228-4a05-b110-2b4b84fcc15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_vectorstore_2d(\n",
    "    vectors, documents, doc_types, colors, title=\"2D Chroma Vector Store Visualization\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Reduce vector embeddings to 2D using t-SNE and return a Plotly figure.\n",
    "\n",
    "    Args:\n",
    "        vectors (ndarray): The high-dimensional vector embeddings.\n",
    "        documents (list): The original text documents (same order as vectors).\n",
    "        doc_types (list): The type of each document, used for hover info and coloring.\n",
    "        colors (list): Color values corresponding to each doc_type.\n",
    "        title (str): Title for the Plotly figure.\n",
    "\n",
    "    Returns:\n",
    "        go.Figure: A Plotly figure object ready to be displayed.\n",
    "    \"\"\"\n",
    "    tsne = TSNE(n_components=2, random_state=42)\n",
    "    reduced_vectors = tsne.fit_transform(vectors)\n",
    "\n",
    "    hover_texts = [\n",
    "        f\"Type: {t}<br>Text: {d[:100]}...\" for t, d in zip(doc_types, documents)\n",
    "    ]\n",
    "\n",
    "    fig = go.Figure(\n",
    "        data=[\n",
    "            go.Scatter(\n",
    "                x=reduced_vectors[:, 0],\n",
    "                y=reduced_vectors[:, 1],\n",
    "                mode=\"markers\",\n",
    "                marker=dict(size=5, color=colors, opacity=0.8),\n",
    "                text=hover_texts,\n",
    "                hoverinfo=\"text\",\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    fig.update_layout(\n",
    "        title=title,\n",
    "        xaxis_title=\"x\",\n",
    "        yaxis_title=\"y\",\n",
    "        width=800,\n",
    "        height=600,\n",
    "        margin=dict(r=20, b=10, l=10, t=40),\n",
    "    )\n",
    "\n",
    "    return fig\n",
    "\n",
    "\n",
    "fig = visualize_vectorstore_2d(vectors, documents, doc_types, colors)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef364b2-92f6-45dd-8983-92962d1c931a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_vectorstore_3d(\n",
    "    vectors, documents, doc_types, colors, title=\"3D Chroma Vector Store Visualization\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Reduce vector embeddings to 3D using t-SNE and return a Plotly 3D scatter plot.\n",
    "\n",
    "    Args:\n",
    "        vectors (ndarray): High-dimensional vector embeddings.\n",
    "        documents (list): Corresponding document texts.\n",
    "        doc_types (list): Document types for labeling and coloring.\n",
    "        colors (list): Color values for each point based on doc_type.\n",
    "        title (str): Title for the Plotly figure.\n",
    "\n",
    "    Returns:\n",
    "        go.Figure: A Plotly 3D scatter plot figure object.\n",
    "    \"\"\"\n",
    "    tsne = TSNE(n_components=3, random_state=42)\n",
    "    reduced_vectors = tsne.fit_transform(vectors)\n",
    "\n",
    "    hover_texts = [\n",
    "        f\"Type: {t}<br>Text: {d[:100]}...\" for t, d in zip(doc_types, documents)\n",
    "    ]\n",
    "\n",
    "    fig = go.Figure(\n",
    "        data=[\n",
    "            go.Scatter3d(\n",
    "                x=reduced_vectors[:, 0],\n",
    "                y=reduced_vectors[:, 1],\n",
    "                z=reduced_vectors[:, 2],\n",
    "                mode=\"markers\",\n",
    "                marker=dict(size=5, color=colors, opacity=0.8),\n",
    "                text=hover_texts,\n",
    "                hoverinfo=\"text\",\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    fig.update_layout(\n",
    "        title=title,\n",
    "        scene=dict(xaxis_title=\"x\", yaxis_title=\"y\", zaxis_title=\"z\"),\n",
    "        width=900,\n",
    "        height=700,\n",
    "        margin=dict(r=20, b=10, l=10, t=40),\n",
    "    )\n",
    "\n",
    "    return fig\n",
    "\n",
    "\n",
    "fig = visualize_vectorstore_3d(vectors, documents, doc_types, colors)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01191b91-7cc4-41f1-8551-39f9d006d19f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_conversational_chain(vectorstore, model_name, temperature=0.7, k=25):\n",
    "    \"\"\"\n",
    "    Set up a Conversational Retrieval Chain using OpenAI LLM, a retriever over the vectorstore, and memory.\n",
    "\n",
    "    Args:\n",
    "        vectorstore (Chroma): The vectorstore containing embedded document chunks.\n",
    "        model_name (str): Name of the OpenAI model to use (e.g., 'gpt-3.5-turbo').\n",
    "        temperature (float): Sampling temperature for generation.\n",
    "        k (int): Number of chunks to retrieve for context.\n",
    "\n",
    "    Returns:\n",
    "        ConversationalRetrievalChain: A configured conversational chain for RAG.\n",
    "    \"\"\"\n",
    "    llm = ChatOpenAI(temperature=temperature, model_name=model_name)\n",
    "    memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "    retriever = vectorstore.as_retriever(search_kwargs={\"k\": k})\n",
    "\n",
    "    return ConversationalRetrievalChain.from_llm(\n",
    "        llm=llm, retriever=retriever, memory=memory\n",
    "    )\n",
    "\n",
    "\n",
    "conversation_chain = create_conversational_chain(vectorstore, model_name=MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c15f1d-9421-40ba-9c8c-98ed89963991",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(question, history):\n",
    "    \"\"\"\n",
    "    Submit a question to the conversational retrieval chain.\n",
    "\n",
    "    Args:\n",
    "        question (str): The user's input question.\n",
    "        history (list): A list of (question, answer) tuples representing the chat history.\n",
    "                        This is not used internally by the chain, but can be maintained externally.\n",
    "\n",
    "    Returns:\n",
    "        str: The assistant's response to the question.\n",
    "    \"\"\"\n",
    "    result = conversation_chain.invoke({\"question\": question})\n",
    "    return result[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e20c40-9118-4a08-ac78-d4a9105d1a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "force_dark_mode = \"\"\"\n",
    "function refresh() {\n",
    "    const url = new URL(window.location);\n",
    "    if (url.searchParams.get('__theme') !== 'dark') {\n",
    "        url.searchParams.set('__theme', 'dark');\n",
    "        window.location.href = url.href;\n",
    "    }\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "view = gr.ChatInterface(chat, type=\"messages\", js=force_dark_mode).launch(\n",
    "    inbrowser=True, share=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3f7e87-9859-49b6-9693-01f296041a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "\n",
    "\n",
    "def create_conversational_chain_with_fallback_prompt(\n",
    "    vectorstore, model_name, temperature=0.7, k=25\n",
    "):\n",
    "    \"\"\"\n",
    "    Creates a conversational retrieval chain with a system prompt that allows fallback to general knowledge.\n",
    "\n",
    "    Args:\n",
    "        vectorstore (Chroma): Your vectorstore for retrieval.\n",
    "        model_name (str): Model name like 'gpt-4' or 'gpt-3.5-turbo'.\n",
    "        temperature (float): Temperature setting for the LLM.\n",
    "        k (int): Number of top documents to retrieve.\n",
    "\n",
    "    Returns:\n",
    "        ConversationalRetrievalChain: The configured chain.\n",
    "    \"\"\"\n",
    "    llm = ChatOpenAI(temperature=temperature, model_name=model_name)\n",
    "    memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "    retriever = vectorstore.as_retriever(search_kwargs={\"k\": k})\n",
    "\n",
    "    system_prompt = (\n",
    "        \"You are a helpful assistant. Use the following retrieved context to answer the user's question. \"\n",
    "        \"If the context does not contain the answer, you may answer using your own knowledge.\"\n",
    "    )\n",
    "\n",
    "    system_message = SystemMessagePromptTemplate.from_template(system_prompt)\n",
    "    human_message = HumanMessagePromptTemplate.from_template(\n",
    "        \"Context:\\n{context}\\n\\nQuestion:\\n{question}\"\n",
    "    )\n",
    "    prompt = ChatPromptTemplate.from_messages([system_message, human_message])\n",
    "\n",
    "    return ConversationalRetrievalChain.from_llm(\n",
    "        llm=llm,\n",
    "        retriever=retriever,\n",
    "        memory=memory,\n",
    "        combine_docs_chain_kwargs={\"prompt\": prompt},\n",
    "    )\n",
    "\n",
    "\n",
    "# Call this once\n",
    "general_conversation_chain = create_conversational_chain_with_fallback_prompt(\n",
    "    vectorstore, model_name=MODEL\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a594b74-791e-44fa-a94d-50648174f2bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "personal-ai-agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
